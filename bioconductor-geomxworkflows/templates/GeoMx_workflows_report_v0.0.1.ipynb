{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc7019f6-3aa6-4aa0-aecd-6477a11e537b",
   "metadata": {},
   "source": [
    "# GeoMX DCC counts QC for project {{ PROJECT_IGF_ID }}\n",
    "* **Notebook version:** v0.0.1\n",
    "* **Created by:** Imperial BRC Genomics Facility\n",
    "* **Maintained by:** Imperial BRC Genomics Facility\n",
    "* **Docker image path:** [Dockerfile](https://github.com/imperial-genomics-facility/igf-dockerfiles/tree/main/bioconductor-geomxworkflows/Dockerfile_v1)\n",
    "* **Notebook code path:** [Templates](https://github.com/imperial-genomics-facility/igf-dockerfiles/tree/main/bioconductor-geomxworkflows/templates)\n",
    "* **Created on:** {{ DATE_TAG }}\n",
    "* **Contact us:** [Imperial BRC Genomics Facility](https://www.imperial.ac.uk/medicine/research-and-impact/facilities/genomics-facility/contact-us/)\n",
    "* **License:** Apache [License 2.0](https://github.com/imperial-genomics-facility/scanpy-notebook-image/blob/master/LICENSE)\n",
    "* **Project name:** {{ PROJECT_IGF_ID }}\n",
    "* **Analysis name:** {{ ANALYSIS_NAME }}\n",
    "\n",
    "Send us your suggestions (or PRs) about how to improve this notebook.\n",
    "\n",
    "Please add the following statement in all publications rif you use any part of this notebook for your analysis: _“The Imperial BRC Genomics Facility has provided resources and support that have contributed to the research results reported within this paper. The Imperial BRC Genomics Facility is supported by NIHR funding to the Imperial Biomedical Research Centre”._\n",
    "\n",
    "## Required inputs\n",
    "\n",
    "Following input files are required for running this notebook:\n",
    "1. **GeoMx DCC count directory:** _{{ GEOMX_DCC_DIR }}_\n",
    "2. **GeoMx annotation file:** _{{ GEOMX_ANNOTATION_FILE }}_\n",
    "3. **PKC file (probe assay metadata describing the gene targets present in the data):** _{{ GEOMX_PKC_FILE }}_\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "* [Line chart of read count data](#Line-chart-of-read-count-data)\n",
    "* [Read count table](#Read-count-table)\n",
    "* [Loading Data to GeoMx workflows](#Loading-Data-to-GeoMx-workflows)\n",
    "* [QC & Pre-processing](#QC-&-Pre-processing)\n",
    "* [Segment QC](#Segment-QC)\n",
    "* [Visualize Segment QC](#Visualize-Segment-QC)\n",
    "* [Display samples with warnings](#Display-samples-with-warnings)\n",
    "* [Remove flagged segments](#Remove-flagged-segments)\n",
    "* [Probe QC](#Probe-QC)\n",
    "* [Create Gene-level Count Data](#Create-Gene-level-Count-Data)\n",
    "* [Limit of Quantification](#Limit-of-Quantification)\n",
    "* [Normalization](#Normalization)\n",
    "* [Unsupervised Analysis](#Unsupervised-Analysis)\n",
    "* [Convert to Seurat object](#Convert-to-Seurat-object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c463b3bc-b292-42a6-9ae2-ea98fbd66845",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading Python library\n",
    "import os\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from IPython.display import HTML\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "alt.renderers.enable(\"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012c6fc7-e18f-44cb-bdd5-93dbbccdebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## anotation processing\n",
    "def reformat_roi_id_and_scan_name(s):\n",
    "    if s['Scan Name'] is None or \\\n",
    "       s['Scan Name'] == 'nan':\n",
    "        s['Scan Name'] = ''\n",
    "    if s['Roi'] is None or \\\n",
    "       s['Roi'] == 'nan':\n",
    "        s['Roi'] = ''\n",
    "    new_roi_id = ''\n",
    "    roi_id = s['Roi']\n",
    "    scan_name = s['Scan Name']\n",
    "    if roi_id != '' and scan_name != '':\n",
    "        roi_id = roi_id.replace('\\\"', '').replace('=', '')\n",
    "        new_roi_id = scan_name + '-' + roi_id\n",
    "    s['Roi'] = new_roi_id\n",
    "    return s\n",
    "\n",
    "def get_formatted_xlsx_for_geomx_workflow(labworksheet_file: str, xlsx_file: str) -> None:\n",
    "    try:\n",
    "        annotation_data = list()\n",
    "        annotation_found = False\n",
    "        with open(labworksheet_file, 'r') as fp:\n",
    "            for line in fp:\n",
    "                if line.startswith('Annotations'):\n",
    "                    annotation_found = True\n",
    "                if annotation_found and \\\n",
    "                   not line.startswith('Annotations'):\n",
    "                    annotation_data.append(line.strip())\n",
    "\n",
    "        annotation_data = '\\n'.join(annotation_data)\n",
    "        csv_data = StringIO(annotation_data)\n",
    "        df = pd.read_csv(csv_data, sep='\\t', header=0)\n",
    "        df['Roi'] = df['Roi'].astype(str)\n",
    "        df['Scan Name'] = df['Scan Name'].astype(str)\n",
    "        #df['Roi'].fillna('', inplace=True)\n",
    "        #df['Scan Name'].fillna('', inplace=True)\n",
    "        df = df.apply(lambda s: reformat_roi_id_and_scan_name(s), axis=1)\n",
    "        df.to_excel(xlsx_file, sheet_name=\"Annotation template\", index=False)\n",
    "    except Exception as e:\n",
    "        raise ValueError(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ecca1-a2c5-48f3-9138-b2dd9aacd36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_formatted_xlsx_for_geomx_workflow(\n",
    "    labworksheet_file='{{ GEOMX_ANNOTATION_FILE }}',\n",
    "    xlsx_file='/tmp/reformatted_annotation.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8a7f9-09ab-4322-99b1-c72dbc3422f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get dcc data and table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1671f8-ab45-4503-879a-7b8d1257f455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_info_from_dcc_and_stats_file(dcc_file: str, stats_file: str) -> dict:\n",
    "    try:\n",
    "        dcc_data = dict()\n",
    "        ## read dcc filet\n",
    "        with open(dcc_file, 'r') as fp:\n",
    "            dcc_file_data = fp.read()\n",
    "        soup = BeautifulSoup(dcc_file_data)\n",
    "        ## get ngs_attributes\n",
    "        ngs_attributes = \\\n",
    "            soup.find_all('ngs_processing_attributes')\n",
    "        if len(ngs_attributes) == 0:\n",
    "            raise ValueError('No ngs_processing_attributes found')\n",
    "        ngs_attributes = \\\n",
    "            ngs_attributes[0].contents\n",
    "        if isinstance(ngs_attributes, list):\n",
    "            ngs_attributes = \\\n",
    "                ngs_attributes[0]\n",
    "        ngs_attributes = [\n",
    "            c.split(',')\n",
    "                for c in ngs_attributes.split('\\n')\n",
    "                    if c != '']\n",
    "        for entry in ngs_attributes:\n",
    "            dcc_data.update({entry[0]: entry[1]})\n",
    "        ## get scan_attributes\n",
    "        scan_attributes =\\\n",
    "            soup.find_all('scan_attributes')\n",
    "        if len(scan_attributes) == 0:\n",
    "            raise ValueError('No scan_attributes found')\n",
    "        scan_attributes = \\\n",
    "            scan_attributes[0].contents\n",
    "        if isinstance(scan_attributes, list):\n",
    "            scan_attributes = \\\n",
    "                scan_attributes[0]\n",
    "        scan_attributes = [\n",
    "            c.split(',')\n",
    "                for c in scan_attributes.split('\\n')\n",
    "                    if c != '']\n",
    "        for entry in scan_attributes:\n",
    "            dcc_data.update({entry[0]: entry[1]})\n",
    "        ## read stats file\n",
    "        if os.path.exists(stats_file):\n",
    "            dedup_entry = ''\n",
    "            with open(stats_file, 'r') as fp:\n",
    "                for line in fp:\n",
    "                    if line.startswith('Reads after dedup'):\n",
    "                        dedup_entry = line.strip()\n",
    "                        break\n",
    "            if len(dedup_entry.split(':')) < 2:\n",
    "                raise ValueError('No dedup entry found: {dedup_entry}')\n",
    "            dedup_entry = \\\n",
    "                dedup_entry.split(':')[1]\n",
    "            dedup_entry = \\\n",
    "                dedup_entry.replace(',', '')\n",
    "            dcc_data.update({'Dedup': dedup_entry})\n",
    "        return dcc_data\n",
    "    except Exception as e:\n",
    "        raise ValueError(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a8d518-f1f1-4efd-a700-5c0486be088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_filter_read(s: pd.Series, props: str, cut_off: int) -> pd.Series:\n",
    "    return np.where(s <= cut_off, props, '')\n",
    "\n",
    "def calculate_saturation(s):\n",
    "    saturation = 0\n",
    "    if s['Aligned'] > 0:\n",
    "        saturation = (1 - s['Dedup'] / s['Aligned']) * 100\n",
    "    s['saturation'] = saturation\n",
    "    return s\n",
    "\n",
    "def calculate_alignment_pct(s):\n",
    "    pct = 0\n",
    "    if s['Aligned'] > 0:\n",
    "        pct = s['Aligned'] / s['Raw'] * 100\n",
    "    s['aligned_pct'] = pct\n",
    "    return s\n",
    "    \n",
    "def generate_read_count_plot_and_table(dcc_base_path: str) -> None:\n",
    "    all_dcc_data = list()\n",
    "    for entry in os.listdir(dcc_base_path):\n",
    "        if entry.endswith('.dcc'):\n",
    "            dcc_path = os.path.join(dcc_base_path, entry)\n",
    "            stats_file = dcc_path.replace('.dcc', '.stats')\n",
    "            entry_dcc_data = \\\n",
    "                combine_info_from_dcc_and_stats_file(\n",
    "                    dcc_file=dcc_path,\n",
    "                    stats_file=stats_file)\n",
    "            all_dcc_data.append(entry_dcc_data)\n",
    "    df = pd.DataFrame(all_dcc_data)\n",
    "    df = df[['ID', 'Raw', 'Trimmed', 'Stitched', 'Aligned', 'Dedup']]\n",
    "    df2 = df.melt('ID', var_name='count_type', value_name='counts')\n",
    "    options = df2['count_type'].drop_duplicates().values.tolist()\n",
    "    selection = alt.selection_multi(fields=['count_type'])\n",
    "    color = alt.condition(selection, alt.Color('count_type:N'), alt.value('lightgray'))\n",
    "    make_selector = alt.Chart(df2).mark_rect().encode(x=alt.X('count_type').title('Track type'), color=color).add_params(selection)\n",
    "\n",
    "    line = \\\n",
    "        alt.Chart(df2).mark_line().encode(\n",
    "            x=alt.X('ID:N').axis(labels=False).title('Roi'),\n",
    "            y=alt.Y('counts:Q').title('Number of reads'),\n",
    "            color=alt.Color('count_type:N').scale(domain=options).title('Track type')).\\\n",
    "        add_params(\n",
    "            selection\n",
    "        ).transform_filter(\n",
    "            selection\n",
    "        )\n",
    "\n",
    "    point = \\\n",
    "        alt.Chart(df2).mark_point().encode(\n",
    "            x=alt.X('ID:N').axis(labels=False).title('Roi'),\n",
    "            y=alt.Y('counts:Q').title('Number of reads'),\n",
    "            color=alt.Color('count_type:N').scale(domain=options).title('Track type'),\n",
    "            tooltip=['ID:N', 'counts:Q', 'count_type:N']).\\\n",
    "        add_params(\n",
    "            selection\n",
    "        ).transform_filter(\n",
    "            selection\n",
    "        )\n",
    "\n",
    "    lower = \\\n",
    "        alt.layer(\n",
    "            line, point).\\\n",
    "        properties(\n",
    "            width=960, height=400)\n",
    "\n",
    "    \n",
    "    plot = alt.vconcat(make_selector, lower)\n",
    "    df.fillna(0, inplace=True)\n",
    "    df['Dedup'] = df['Dedup'].astype(int)\n",
    "    df['Aligned'] = df['Aligned'].astype(int)\n",
    "    df =  df.apply(lambda s: calculate_saturation(s), axis=1)\n",
    "    df['Raw'] = df['Raw'].astype(int)\n",
    "    df =  df.apply(lambda s: calculate_alignment_pct(s), axis=1)\n",
    "    html = df.set_index('ID').\\\n",
    "        style.\\\n",
    "        apply(style_filter_read, props='color:red;', cut_off=1000, axis=0, subset=['Raw',]).\\\n",
    "         apply(style_filter_read, props='background-color:#ffffb3;', cut_off=1000, axis=0, subset=['Raw',]).\\\n",
    "         apply(style_filter_read, props='color:red;', cut_off=80.0, axis=0, subset=['aligned_pct',]).\\\n",
    "         apply(style_filter_read, props='background-color:#ffffb3;', cut_off=80.0, axis=0, subset=['aligned_pct',]).\\\n",
    "         apply(style_filter_read, props='color:red;', cut_off=50.0, axis=0, subset=['saturation',]).\\\n",
    "         apply(style_filter_read, props='background-color:#ffffb3;', cut_off=50.0, axis=0, subset=['saturation',]).\\\n",
    "         to_html()\n",
    "    return plot, html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a7b14-c081-4a1d-9a55-0260e53ec430",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot, html = generate_read_count_plot_and_table('{{ GEOMX_DCC_DIR }}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4793e514-9b33-4da9-a7ea-6eba8cd0b03f",
   "metadata": {},
   "source": [
    "### Line chart of read count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1da09c-0b31-40b3-a501-e0b63b55d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a810bea6-dd8f-4695-9aaa-5f600aeaeb8f",
   "metadata": {},
   "source": [
    "### Read count table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c4ee1a-d73a-4bb2-92f0-5b34e7eff7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '<details><summary>Click to expand summary table</summary>' + html + '</details>'\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3771d1e-cf9b-4bc5-975f-be859a0eb8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b590007e-2d7d-4382-82cc-8cefa7f6541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "suppressMessages(library(NanoStringNCTools))\n",
    "suppressMessages(library(GeomxTools))\n",
    "suppressMessages(library(GeoMxWorkflows))\n",
    "suppressMessages(library(knitr))\n",
    "suppressMessages(library(dplyr))\n",
    "suppressMessages(library(ggforce))\n",
    "suppressMessages(library(ggplot2))\n",
    "suppressMessages(library(Seurat))\n",
    "suppressMessages(library(SeuratData))\n",
    "suppressMessages(library(SeuratDisk))\n",
    "suppressMessages(library(reshape2))\n",
    "suppressMessages(library(cowplot))\n",
    "suppressMessages(library(umap))\n",
    "suppressMessages(library(Rtsne))\n",
    "suppressMessages(library(pheatmap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e6fd1-b329-4471-bddf-ce9049c3704e",
   "metadata": {},
   "source": [
    "### Loading Data to GeoMx workflows\n",
    "\n",
    "* DCCs files - expression count data and sequencing quality metadata\n",
    "* PKCs file(s) - probe assay metadata describing the gene targets present in the data, PKC files can be found here\n",
    "* Annotation file - segment area/nuclei count, and other tissue characteristics. If working with a new dataset, use the lab worksheet from the GeoMx instrument study readout package, as the annotation order of NTCs is important to ensure proper processing of files.\n",
    "\n",
    "All of the expression, annotation, and probe information are now linked and stored together into a single data object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce1601-6496-4c63-9621-9fd71ec35383",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "DCCFiles <- dir(file.path(\"{{ GEOMX_DCC_DIR }}\"), pattern = \".dcc$\",\n",
    "                full.names = TRUE, recursive = TRUE)\n",
    "PKCFiles <- file.path('{{ GEOMX_PKC_FILE }}')\n",
    "SampleAnnotationFile <-\n",
    "    file.path('/tmp/reformatted_annotation.xlsx')\n",
    "# load data\n",
    "data <-\n",
    "    readNanoStringGeoMxSet(dccFiles = DCCFiles,\n",
    "                           pkcFiles = PKCFiles,\n",
    "                           phenoDataFile = SampleAnnotationFile,\n",
    "                           phenoDataSheet = \"Annotation template\",\n",
    "                           phenoDataDccColName = \"Sample_ID\",\n",
    "                           protocolDataColNames = c(\"Roi\", \"Aoi\"),\n",
    "                           experimentDataColNames = c(\"Panel\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1e6675-1e97-412f-9e46-0049ee0fda46",
   "metadata": {},
   "source": [
    "First let’s access the PKC files, to ensure that the expected PKCs have been loaded for this study. For the demo data we are using the input pkc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d82b3-d21f-42c1-aa55-59f18f00f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "pkcs <- annotation(data)\n",
    "modules <- gsub(\".pkc\", \"\", pkcs)\n",
    "kable(data.frame(PKCs = pkcs, modules = modules))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab337a2f-a7dd-48af-9c83-13abe9a0e30c",
   "metadata": {},
   "source": [
    "### QC & Pre-processing \n",
    "The steps above encompass the standard pre-processing workflow for GeoMx data. In short, they represent the selection of ROI/AOI segments and genes based on quality control (QC) or limit of quantification (LOQ) metrics and data normalization. Before we begin, we will shift any expression counts with a value of 0 to 1 to enable in downstream transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c315fb25-2f86-4262-b05a-74678e9bb6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Shift counts to one\n",
    "data <- shiftCountsOne(data, useDALogic = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052b4d59-ad34-4403-8057-0600057acd16",
   "metadata": {},
   "source": [
    "### Segment QC\n",
    "Every ROI/AOI segment will be tested for:\n",
    "* Raw sequencing reads: segments with <1000 raw reads\n",
    "* % Aligned,% Trimmed, or % Stitched sequencing reads: segments below ~80%\n",
    "* % Sequencing saturation ([1-deduplicated reads/aligned reads]%): segments below ~50% require additional sequencing to capture full sample diversity and are not typically analyzed until improved.\n",
    "* Negative Count: this is the geometric mean of the several unique negative probes in the GeoMx panel that do not target mRNA and establish the background count level per segment; segments with low negative counts (1-10) are not necessarily removed but may be studied closer for low endogenous gene signal and/or insufficient tissue sampling\n",
    "* No Template Control (NTC) count: values >1,000 could indicate contamination for the segments associated with this NTC; however, in cases where the NTC count is between 1,000- 10,000, the segments may be used if the NTC data is uniformly low (e.g. 0-2 counts for all probes).\n",
    "* Nuclei: >100 nuclei per segment is generally recommended; however, this cutoff is highly study/tissue dependent and may need to be reduced; what is most important is consistency in the nuclei distribution for segments within the study.\n",
    "* Area: generally correlates with nuclei; a strict cutoff is not generally applied based on area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f809f3-f1d8-4a44-823c-a0df42947f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "qc_params <- list(\n",
    "    minSegmentReads = 1000,\n",
    "    percentTrimmed = 80,\n",
    "    percentStiched = 80,\n",
    "    percentAligned = 80,\n",
    "    percentSaturation = 50,\n",
    "    minNegativeCount = 1,\n",
    "    maxNegativeCount = 1000,\n",
    "    minNuclei = 100,\n",
    "    minArea = 1000)\n",
    "\n",
    "data <- setSegmentQCFlags(\n",
    "    data,\n",
    "    qcCutoffs = qc_params)\n",
    "\n",
    "# Collate QC Results\n",
    "QCResults <- protocolData(data)[[\"QCFlags\"]]\n",
    "flag_columns <- colnames(QCResults)\n",
    "QC_Summary <- data.frame(Pass = colSums(!QCResults[, flag_columns]),\n",
    "                         Warning = colSums(QCResults[, flag_columns]))\n",
    "QCResults$QCStatus <- apply(QCResults, 1L, function(x) {\n",
    "    ifelse(sum(x) == 0L, \"PASS\", \"WARNING\")\n",
    "})\n",
    "QC_Summary[\"TOTAL FLAGS\", ] <-\n",
    "    c(sum(QCResults[, \"QCStatus\"] == \"PASS\"),\n",
    "      sum(QCResults[, \"QCStatus\"] == \"WARNING\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf0fd18-1f1e-4f49-b2bc-044c83797f2e",
   "metadata": {},
   "source": [
    "### Visualize Segment QC\n",
    "Before excluding any low-performing ROI/AOI segments, we visualize the distributions of the data for the different QC parameters. Note that the “Select Segment QC” and “Visualize Segment QC” sections are performed in parallel to fully understand low-performing segments for a given study. Iteration may follow to select the study-specific QC cutoffs.\n",
    "\n",
    "For QC visualization, we write a quick function to draw histograms of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef5d34-0f16-420b-a406-996703b3a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "col_by <- \"Segment\"\n",
    "\n",
    "# Graphical summaries of QC statistics plot function\n",
    "QC_histogram <- function(assay_data = NULL,\n",
    "                         annotation = NULL,\n",
    "                         fill_by = NULL,\n",
    "                         thr = NULL,\n",
    "                         scale_trans = NULL) {\n",
    "    plt <- ggplot(assay_data,\n",
    "                  aes_string(x = paste0(\"unlist(`\", annotation, \"`)\"),\n",
    "                             fill = fill_by)) +\n",
    "        geom_histogram(bins = 50) +\n",
    "        geom_vline(xintercept = thr, lty = \"dashed\", color = \"black\") +\n",
    "        theme_bw() + guides(fill = \"none\") +\n",
    "        facet_wrap(as.formula(paste(\"~\", fill_by)), nrow = 4) +\n",
    "        labs(x = annotation, y = \"Segments, #\", title = annotation)\n",
    "    if(!is.null(scale_trans)) {\n",
    "        plt <- plt +\n",
    "            scale_x_continuous(trans = scale_trans)\n",
    "    }\n",
    "    plt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb37d15-c626-45a2-80a0-7ba21580e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 1480 -h 780 -u px\n",
    "plot(QC_histogram(sData(data), \"Trimmed (%)\", col_by, 80))\n",
    "plot(QC_histogram(sData(data), \"Stitched (%)\", col_by, 80))\n",
    "plot(QC_histogram(sData(data), \"Aligned (%)\", col_by, 80))\n",
    "plot(QC_histogram(sData(data), \"Saturated (%)\", col_by, 50) +\n",
    "   labs(title = \"Sequencing Saturation (%)\",\n",
    "        x = \"Sequencing Saturation (%)\"))\n",
    "plot(QC_histogram(sData(data), \"Area\", col_by, 1000, scale_trans = \"log10\"))\n",
    "plot(QC_histogram(sData(data), \"Nuclei\", col_by, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895aa887-4a2e-4b03-9ec1-2385a8a15240",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 1480 -h 780 -u px\n",
    "# calculate the negative geometric means for each module\n",
    "negativeGeoMeans <- \n",
    "    esBy(negativeControlSubset(data), \n",
    "         GROUP = \"Module\", \n",
    "         FUN = function(x) { \n",
    "             assayDataApply(x, MARGIN = 2, FUN = ngeoMean, elt = \"exprs\") \n",
    "         }) \n",
    "protocolData(data)[[\"NegGeoMean\"]] <- negativeGeoMeans\n",
    "\n",
    "# explicitly copy the Negative geoMeans from sData to pData\n",
    "negCols <- paste0(\"NegGeoMean_\", modules)\n",
    "pData(data)[, negCols] <- sData(data)[[\"NegGeoMean\"]]\n",
    "for(ann in negCols) {\n",
    "    plt <- QC_histogram(pData(data), ann, col_by, 2, scale_trans = \"log10\")\n",
    "    print(plt)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00708b44-67ab-4c2d-9a93-ff2c56c3ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# detatch neg_geomean columns ahead of aggregateCounts call\n",
    "pData(data) <- pData(data)[, !colnames(pData(data)) %in% negCols]\n",
    "\n",
    "# show all NTC values, Freq = # of Segments with a given NTC count:\n",
    "kable(table(NTC_Count = sData(data)$NTC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1688b493-9e47-4ea6-b580-6c4e18eac114",
   "metadata": {},
   "source": [
    "Finally we plot all of the QC Summary information in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f8a815-2fd7-4d8e-bdd6-a4a883085868",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "kable(QC_Summary, caption = \"QC Summary Table for each Segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d0ace-992a-47cf-a444-ac51989ad0cd",
   "metadata": {},
   "source": [
    "### Display samples with warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c1125-7b2a-4a88-98bf-7754cd936142",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -o a\n",
    "a = pData(data[, QCResults$QCStatus == \"WARNING\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9c2abc-3ed8-45cc-a6e5-1e04abed705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = a[['Slide Name', 'Scan Name','Segment']].fillna('').to_html()\n",
    "html = '<details><summary>Click to expand summary table</summary>' + html + '</details>'\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b10afc-bd69-4952-b594-644924f73182",
   "metadata": {},
   "source": [
    "### Remove flagged segments\n",
    "\n",
    "As the final step in Segment QC, we remove flagged segments that do not meet our QC cutoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81128737-d6aa-4039-a0bd-50acb150edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "data <- data[, QCResults$QCStatus == \"PASS\"]\n",
    "\n",
    "# Subsetting our dataset has removed samples which did not pass QC\n",
    "dim(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45572f4-5e18-4c03-bf02-7896e936b064",
   "metadata": {},
   "source": [
    "### Probe QC\n",
    "Before we summarize our data into gene-level count data, we will remove low-performing probes. In short, this QC is an outlier removal process, whereby probes are either removed entirely from the study (global) or from specific segments (local). The QC applies to gene targets for which there are multiple distinct probes representing the count for a gene per segment. In WTA data, one specific probe exists per target gene; thus, Probe QC does not apply to the endogenous genes in the panel. Rather, it is performed on the negative control probes; there are multiple probes representing our negative controls, which do not target any sequence in the genome. These probes enable calculation of the background per segment and will be important for determining gene detection downstream.\n",
    "\n",
    "After Probe QC, there will always remain at least one probe representing every gene target. In other words, Probe QC never removes genes from your data\n",
    "\n",
    "#### Set Probe QC Flags\n",
    "\n",
    "A probe is removed globally from the dataset if either of the following is true:\n",
    "\n",
    "* the geometric mean of that probe’s counts from all segments divided by the geometric mean of all probe counts representing the target from all segments is less than 0.1\n",
    "* the probe is an outlier according to the Grubb’s test in at least 20% of the segments\n",
    "\n",
    "A probe is removed locally (from a given segment) if the probe is an outlier according to the Grubb’s test in that segment.\n",
    "\n",
    "We do not typically adjust these QC parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88588fa2-22d1-4c5f-8504-f7997b0ab917",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Generally keep the qcCutoffs parameters unchanged. Set removeLocalOutliers to \n",
    "# FALSE if you do not want to remove local outliers\n",
    "data <- setBioProbeQCFlags(data, \n",
    "                               qcCutoffs = list(minProbeRatio = 0.1,\n",
    "                                                percentFailGrubbs = 20), \n",
    "                               removeLocalOutliers = TRUE)\n",
    "\n",
    "ProbeQCResults <- fData(data)[[\"QCFlags\"]]\n",
    "\n",
    "# Define QC table for Probe QC\n",
    "qc_df <- data.frame(Passed = sum(rowSums(ProbeQCResults[, -1]) == 0),\n",
    "                    Global = sum(ProbeQCResults$GlobalGrubbsOutlier),\n",
    "                    Local = sum(rowSums(ProbeQCResults[, -2:-1]) > 0\n",
    "                                & !ProbeQCResults$GlobalGrubbsOutlier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5936a-77a7-4708-af51-84b3ca4e7d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "kable(qc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5932b5-cb56-40bb-8110-a01c05988c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#Subset object to exclude all that did not pass Ratio & Global testing\n",
    "ProbeQCPassed <- \n",
    "    subset(data, \n",
    "           fData(data)[[\"QCFlags\"]][,c(\"LowProbeRatio\")] == FALSE &\n",
    "               fData(data)[[\"QCFlags\"]][,c(\"GlobalGrubbsOutlier\")] == FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373e49d-d766-4289-94a8-494408961413",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "dim(ProbeQCPassed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adaa022-17cb-4727-aedf-375800c4f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "data <- ProbeQCPassed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a8351-1db7-4b83-93b7-8532697b06fc",
   "metadata": {},
   "source": [
    "### Create Gene-level Count Data\n",
    "\n",
    "With our Probe QC steps complete, we will generate a gene-level count matrix. The count for any gene with multiple probes per segment is calculated as the geometric mean of those probes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b879c-ccee-438a-932e-de327c6cbf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Check how many unique targets the object has\n",
    "length(unique(featureData(data)[[\"TargetName\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482beb9-8729-4f63-8d2b-5b093fdd7450",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# collapse to targets\n",
    "target_data <- aggregateCounts(data)\n",
    "dim(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1f812-53c5-4630-af48-493a2f386430",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "exprs(target_data)[1:5, 1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89304fd-d58a-465f-a10c-43a3ed6a5ab0",
   "metadata": {},
   "source": [
    "### Limit of Quantification\n",
    "In addition to Segment and Probe QC, we also determine the limit of quantification (LOQ) per segment. The LOQ is calculated based on the distribution of negative control probes and is intended to approximate the quantifiable limit of gene expression per segment. Please note that this process is more stable in larger segments. Likewise, the LOQ may not be as accurately reflective of true signal detection rates in segments with low negative probe counts (ex: <2). The formula for calculating the LOQ in the ith segment is:\n",
    "\n",
    "$$LOQi=geomean(NegProbei)∗geoSD(NegProbei)^n$$\n",
    "\n",
    "We typically use 2 geometric standard deviations (n=2) above the geometric mean as the LOQ, which is reasonable for most studies. We also recommend that a minimum LOQ of 2 be used if the LOQ calculated in a segment is below this threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9c58d-402a-43fe-84a5-fa07fefadd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Define LOQ SD threshold and minimum value\n",
    "cutoff <- 2\n",
    "minLOQ <- 2\n",
    "\n",
    "# Calculate LOQ per module tested\n",
    "LOQ <- data.frame(row.names = colnames(target_data))\n",
    "for(module in modules) {\n",
    "    vars <- paste0(c(\"NegGeoMean_\", \"NegGeoSD_\"),\n",
    "                   module)\n",
    "    if(all(vars[1:2] %in% colnames(pData(target_data)))) {\n",
    "        LOQ[, module] <-\n",
    "            pmax(minLOQ,\n",
    "                 pData(target_data)[, vars[1]] * \n",
    "                     pData(target_data)[, vars[2]] ^ cutoff)\n",
    "    }\n",
    "}\n",
    "pData(target_data)$LOQ <- LOQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56220c6-cc60-452a-8d15-2206f779f8c4",
   "metadata": {},
   "source": [
    "### Filtering LOQ\n",
    "After determining the limit of quantification (LOQ) per segment, we recommend filtering out either segments and/or genes with abnormally low signal. Filtering is an important step to focus on the true biological data of interest.\n",
    "\n",
    "We determine the number of genes detected in each segment across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da786c6-9db7-4d42-8a80-3ade43e60036",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "LOQ_Mat <- c()\n",
    "for(module in modules) {\n",
    "    ind <- fData(target_data)$Module == module\n",
    "    Mat_i <- t(esApply(target_data[ind, ], MARGIN = 1,\n",
    "                       FUN = function(x) {\n",
    "                           x > LOQ[, module]\n",
    "                       }))\n",
    "    LOQ_Mat <- rbind(LOQ_Mat, Mat_i)\n",
    "}\n",
    "# ensure ordering since this is stored outside of the geomxSet\n",
    "LOQ_Mat <- LOQ_Mat[fData(target_data)$TargetName, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef2ff8-e6ba-4fdb-aec2-445fb491c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Save detection rate information to pheno data\n",
    "pData(target_data)$GenesDetected <- \n",
    "    colSums(LOQ_Mat, na.rm = TRUE)\n",
    "pData(target_data)$GeneDetectionRate <-\n",
    "    pData(target_data)$GenesDetected / nrow(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e7574e-f94e-4f4d-85bb-2c7c1cf503c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Determine detection thresholds: 1%, 5%, 10%, 15%, >15%\n",
    "pData(target_data)$DetectionThreshold <- \n",
    "    cut(pData(target_data)$GeneDetectionRate,\n",
    "        breaks = c(0, 0.01, 0.05, 0.1, 0.15, 1),\n",
    "        labels = c(\"<1%\", \"1-5%\", \"5-10%\", \"10-15%\", \">15%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b20cc67-9db5-4964-b569-6d00bb484eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 800 -h 600 -u px\n",
    "# stacked bar plot of different cut points (1%, 5%, 10%, 15%)\n",
    "ggplot(pData(target_data),\n",
    "       aes(x = DetectionThreshold)) +\n",
    "    geom_bar(aes(fill = Segment)) +\n",
    "    geom_text(stat = \"count\", aes(label = ..count..), vjust = -0.5) +\n",
    "    theme_bw() +\n",
    "    scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n",
    "    labs(x = \"Gene Detection Rate\",\n",
    "         y = \"Segments, #\",\n",
    "         fill = \"Segment Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1844ab-7961-4ab0-a9b3-d09961ef3f83",
   "metadata": {},
   "source": [
    "Now creating a table of Rois which are going to be impacted by each threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dcd6d9-8d9e-4319-8f13-f59ce52e62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "kable(table(pData(target_data)$DetectionThreshold,\n",
    "            pData(target_data)$Segment))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3c8be-3e7e-420b-ae18-fa93cc05fc9b",
   "metadata": {},
   "source": [
    "Now remove segments with less than 5% of the genes detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13627f-d0a4-4726-ad47-528f4ed94770",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "target_data <-\n",
    "    target_data[, pData(target_data)$GeneDetectionRate >= .05]\n",
    "\n",
    "dim(target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329df07a-a828-4261-9e4a-ef9d7a4b7b8c",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "We will now normalize the GeoMx data for downstream visualizations and differential expression. The two common methods for normalization of DSP-NGS RNA data are i) quartile 3 (Q3) or ii) background normalization.\n",
    "\n",
    "Both of these normalization methods estimate a normalization factor per segment to bring the segment data distributions together. More advanced methods for normalization and modeling are under active development. However, for most studies, these methods are sufficient for understanding differences between biological classes of segments and samples.\n",
    "\n",
    "Q3 normalization is typically the preferred normalization strategy for most DSP-NGS RNA studies. Given the low negative probe counts in this particular dataset as shown during Segment QC, we would further avoid background normalization as it may be less stable.\n",
    "\n",
    "Before normalization, we will explore the relationship between the upper quartile (Q3) of the counts in each segment with the geometric mean of the negative control probes in the data. Ideally, there should be a separation between these two values to ensure we have stable measure of Q3 signal. If you do not see sufficient separation between these values, you may consider more aggressive filtering of low signal segments/genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948d9d0-fa17-4677-b8b9-2d3622c6c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 1280 -h 800 -u px\n",
    "# Graph Q3 value vs negGeoMean of Negatives\n",
    "ann_of_interest <- \"Segment\"\n",
    "negativeProbefData <- subset(fData(target_data), CodeClass == \"Negative\")\n",
    "neg_probes <- unique(negativeProbefData$TargetName)\n",
    "Stat_data <- \n",
    "    data.frame(row.names = colnames(exprs(target_data)),\n",
    "               Segment = colnames(exprs(target_data)),\n",
    "               Annotation = pData(target_data)[, ann_of_interest],\n",
    "               Q3 = unlist(apply(exprs(target_data), 2,\n",
    "                                 quantile, 0.75, na.rm = TRUE)),\n",
    "               NegProbe = exprs(target_data)[neg_probes, ])\n",
    "Stat_data_m <- melt(Stat_data, measure.vars = c(\"Q3\", \"NegProbe\"),\n",
    "                    variable.name = \"Statistic\", value.name = \"Value\")\n",
    "plt1 <- ggplot(Stat_data_m,\n",
    "               aes(x = Value, fill = Statistic)) +\n",
    "    geom_histogram(bins = 40) + theme_bw() +\n",
    "    scale_x_continuous(trans = \"log2\") +\n",
    "    facet_wrap(~Annotation, nrow = 1) + \n",
    "    scale_fill_brewer(palette = 3, type = \"qual\") +\n",
    "    labs(x = \"Counts\", y = \"Segments, #\")\n",
    "plt2 <- ggplot(Stat_data,\n",
    "               aes(x = NegProbe, y = Q3, color = Annotation)) +\n",
    "    geom_abline(intercept = 0, slope = 1, lty = \"dashed\", color = \"darkgray\") +\n",
    "    geom_point() + guides(color = \"none\") + theme_bw() +\n",
    "    scale_x_continuous(trans = \"log2\") + \n",
    "    scale_y_continuous(trans = \"log2\") +\n",
    "    theme(aspect.ratio = 1) +\n",
    "    labs(x = \"Negative Probe GeoMean, Counts\", y = \"Q3 Value, Counts\")\n",
    "plt3 <- ggplot(Stat_data,\n",
    "               aes(x = NegProbe, y = Q3 / NegProbe, color = Annotation)) +\n",
    "    geom_hline(yintercept = 1, lty = \"dashed\", color = \"darkgray\") +\n",
    "    geom_point() + theme_bw() +\n",
    "    scale_x_continuous(trans = \"log2\") + \n",
    "    scale_y_continuous(trans = \"log2\") +\n",
    "    theme(aspect.ratio = 1) +\n",
    "    labs(x = \"Negative Probe GeoMean, Counts\", y = \"Q3/NegProbe Value, Counts\")\n",
    "btm_row <- plot_grid(plt2, plt3, nrow = 1, labels = c(\"B\", \"\"),\n",
    "                     rel_widths = c(0.43,0.57))\n",
    "plot_grid(plt1, btm_row, ncol = 1, labels = c(\"A\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3421a8-9762-47a7-bf79-bbbbd526efa5",
   "metadata": {},
   "source": [
    "Next, we normalize our data. We will use Q3 normalized data moving forward. We use the normalize function from NanoStringNCTools to create normalization factors reflecting each data type. Upper quartile (Q3) normalization is performed using norm_method = \"quant\" setting the desiredQuantile flag to 0.75. Other quantiles could be specified by changing that value. We save the normalized data to a specific slot using toELT = \"q_norm\". Similarly background normalization is performed by setting norm_method = \"neg\" and toElt = \"neg_norm\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df434e68-5947-420f-bb73-bf898157be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Q3 norm (75th percentile) for WTA/CTA  with or without custom spike-ins\n",
    "target_data <- normalize(target_data ,\n",
    "                          norm_method = \"quant\", \n",
    "                             desiredQuantile = .75,\n",
    "                             toElt = \"q_norm\")\n",
    "\n",
    "# Background normalization for WTA/CTA without custom spike-in\n",
    "target_data <- normalize(target_data ,\n",
    "                             norm_method = \"neg\", \n",
    "                             fromElt = \"exprs\",\n",
    "                             toElt = \"neg_norm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc1257d-5a22-450e-9d0d-7216ba30d898",
   "metadata": {},
   "source": [
    "To demonstrate the effects of normalization, we graph representative box plots of the data for individual segments before and after normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2cc2e-12cb-451f-b582-1d473ee78940",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 1080 -h 600 -u px\n",
    "# visualize the first 10 segments with each normalization method\n",
    "boxplot(exprs(target_data)[,1:10],\n",
    "        col = \"#9EDAE5\", main = \"Raw Counts\",\n",
    "        log = \"y\", names = 1:10, xlab = \"Segment\",\n",
    "        ylab = \"Counts, Raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d49ec4-7a75-47ed-a847-8d6af19d9386",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 1080 -h 600 -u px\n",
    "boxplot(assayDataElement(target_data[,1:10], elt = \"q_norm\"),\n",
    "        col = \"#2CA02C\", main = \"Q3 Norm Counts\",\n",
    "        log = \"y\", names = 1:10, xlab = \"Segment\",\n",
    "        ylab = \"Counts, Q3 Normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf4394-253d-45ea-9017-bd9b83afe06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 1080 -h 600 -u px\n",
    "boxplot(assayDataElement(target_data[,1:10], elt = \"neg_norm\"),\n",
    "        col = \"#FF7F0E\", main = \"Neg Norm Counts\",\n",
    "        log = \"y\", names = 1:10, xlab = \"Segment\",\n",
    "        ylab = \"Counts, Neg. Normalized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8a0ca-4dd6-43db-bbe0-e32a97165c44",
   "metadata": {},
   "source": [
    "### Unsupervised Analysis\n",
    "#### UMAP & t-SNE\n",
    "One common approach to understanding high-plex data is dimension reduction. Two common methods are UMAP and tSNE, which are non-orthogonally constrained projections that cluster samples based on overall gene expression. In this study, we see by either UMAP (from the umap package) or tSNE (from the Rtsne package), clusters of segments related to structure (glomeruli or tubules) and disease status (normal or diabetic kidney disease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ffef62-187e-460b-b61e-e423e3d287c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "n_neighbors = 15\n",
    "s = ncol(target_data)\n",
    "if (n_neighbors > s){\n",
    "    n_neighbors <- s\n",
    "}\n",
    "n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6910e6f-0da8-405e-940b-dd04b104f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 800 -h 600 -u px\n",
    "# update defaults for umap to contain a stable random_state (seed)\n",
    "custom_umap <- umap::umap.defaults\n",
    "custom_umap$random_state <- 42\n",
    "custom_umap$n_neighbors <- n_neighbors\n",
    "# run UMAP\n",
    "umap_out <-\n",
    "    umap(t(log2(assayDataElement(target_data , elt = \"q_norm\"))),  \n",
    "         config = custom_umap)\n",
    "pData(target_data)[, c(\"UMAP1\", \"UMAP2\")] <- umap_out$layout[, c(1,2)]\n",
    "ggplot(pData(target_data),\n",
    "       aes(x = UMAP1, y = UMAP2, color = Segment)) +\n",
    "    geom_point(size = 3) +\n",
    "    theme_bw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adbde90-afe9-41fc-9050-c40393341ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 800 -h 600 -u px\n",
    "# run tSNE\n",
    "set.seed(42) # set the seed for tSNE as well\n",
    "tsne_out <-\n",
    "    Rtsne(t(log2(assayDataElement(target_data , elt = \"q_norm\"))),\n",
    "          perplexity = ncol(target_data)*.15)\n",
    "pData(target_data)[, c(\"tSNE1\", \"tSNE2\")] <- tsne_out$Y[, c(1,2)]\n",
    "ggplot(pData(target_data),\n",
    "       aes(x = tSNE1, y = tSNE2, color = Segment)) +\n",
    "    geom_point(size = 3) +\n",
    "    theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f34501a-cd43-49ba-a8fa-85415f42a2e4",
   "metadata": {},
   "source": [
    "#### Clustering high CV Genes\n",
    "Another approach to explore the data is to calculate the coefficient of variation (CV) for each gene (g) using the formula: $$CVg=SDg/mean_g$$ We then identify genes with high CVs that should have large differences across the various profiled segments. This unbiased approach can reveal highly variable genes across the study.\n",
    "\n",
    "We plot the results using unsupervised hierarchical clustering, displayed as a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55573c-85ac-4fde-a0ec-e0e6682f22cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# create a log2 transform of the data for analysis\n",
    "assayDataElement(object = target_data, elt = \"log_q\") <-\n",
    "    assayDataApply(target_data, 2, FUN = log, base = 2, elt = \"q_norm\")\n",
    "# create CV function\n",
    "calc_CV <- function(x) {sd(x) / mean(x)}\n",
    "CV_dat <- assayDataApply(target_data,\n",
    "                         elt = \"log_q\", MARGIN = 1, calc_CV)\n",
    "# show the highest CD genes and their CV values\n",
    "sort(CV_dat, decreasing = TRUE)[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bde2c3-384e-4629-9af6-bb5daf8b20b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 800 -h 600 -u px\n",
    "# Identify genes in the top 3rd of the CV values\n",
    "GOI <- names(CV_dat)[CV_dat > quantile(CV_dat, 0.8)]\n",
    "pheatmap(assayDataElement(target_data[GOI, ], elt = \"log_q\"),\n",
    "         scale = \"row\", \n",
    "         show_rownames = FALSE, show_colnames = FALSE,\n",
    "         border_color = NA,\n",
    "         clustering_method = \"average\",\n",
    "         clustering_distance_rows = \"correlation\",\n",
    "         clustering_distance_cols = \"correlation\",\n",
    "         color = colorRampPalette(c(\"purple3\", \"blue\", \"yellow2\"))(120)\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31fbbb7-613b-4ce1-b5c0-a87d7ff03e83",
   "metadata": {},
   "source": [
    "### Convert to Seurat object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c63c7b-a8d2-47d3-952c-4dec7e7c73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "seuratObj <- as.Seurat(target_data, normData = \"q_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5f8239-0519-4503-b719-9419ae1235c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 600 -h 500 -u px\n",
    "#All Seurat functionality is available after coercing. Outputs might differ if the ident value is set or not.\n",
    "VlnPlot(seuratObj, features = \"nCount_GeoMx\", pt.size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deee27e-b55e-4777-8ada-e65eed653929",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "npcs = 50\n",
    "n_neighbors = 30\n",
    "s = ncol(target_data)\n",
    "if (npcs > s){\n",
    "    npcs <- s - 1\n",
    "}\n",
    "if (n_neighbors > s){\n",
    "    n_neighbors <- s\n",
    "}\n",
    "\n",
    "seuratObj <- suppressMessages(FindVariableFeatures(seuratObj, verbose = FALSE))\n",
    "seuratObj <- suppressMessages(ScaleData(seuratObj))\n",
    "seuratObj <- suppressMessages(RunPCA(seuratObj, assay = \"GeoMx\", npcs = npcs, verbose = TRUE))\n",
    "seuratObj <- suppressMessages(FindNeighbors(seuratObj, verbose = FALSE, reduction = \"pca\", dims = seq_len(npcs)))\n",
    "seuratObj <- suppressMessages(FindClusters(seuratObj, verbose = FALSE))\n",
    "seuratObj <- suppressMessages(RunUMAP(seuratObj, n.neighbors = npcs, reduction = \"pca\", verbose = FALSE, dims = seq_len(npcs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dcdc23-8b80-4751-867c-f7f8eea22be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 800 -h 600 -u px\n",
    "DimPlot(seuratObj, reduction = \"umap\", label = TRUE, label.size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b0ed2-22ef-4165-b256-052e53b0a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 800 -h 600 -u px\n",
    "DimPlot(seuratObj, reduction = \"umap\", label = TRUE, group.by = \"Segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e84fc-1aac-420b-b5d8-1a41b25b2878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
